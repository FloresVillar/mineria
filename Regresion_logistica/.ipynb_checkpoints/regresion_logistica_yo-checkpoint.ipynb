{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60b1200-cfa9-48d1-8068-94d497de92bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40  50  60 100 150 200] (6,)\n",
      "[0 0 0 1 1 1]\n",
      "X\n",
      "[[ 1.         -1.03407298]\n",
      " [ 1.         -0.86172748]\n",
      " [ 1.         -0.68938199]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.86172748]\n",
      " [ 1.          1.72345497]]\n",
      "theta :\n",
      "[0.03803634 1.10265147]\n",
      "Odds Ratio: 3.0121\n",
      "Interpretación: Por cada unidad de ingreso extra, los 'Odds' de aceptar el préstamo suben un 201.21%\n",
      "Si el ingreso sube 10 unidades, los nuevos Odds son: 15370.7309\n",
      "metricas\n",
      "{'matriz': [[np.int64(3), np.int64(0)], [np.int64(0), np.int64(3)]], 'accuracy': np.float64(1.0), 'precision': np.float64(1.0), 'recall': np.float64(1.0), 'f1': np.float64(1.0)}\n",
      "   N-  P+\n",
      "-   3   0\n",
      "+   0   3\n",
      "     Métrica  Valor\n",
      "0   accuracy    1.0\n",
      "1  precision    1.0\n",
      "2     recall    1.0\n",
      "3         f1    1.0\n",
      "VIF:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-----------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 234\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVIF:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    233\u001b[39m df_vif = pd.DataFrame(datos.data,columns=datos.feature_names)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m analisis_vif = \u001b[43mvif_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_vif\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mprint\u001b[39m(analisis_vif)\n\u001b[32m    236\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.33\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 197\u001b[39m, in \u001b[36mvif_\u001b[39m\u001b[34m(df_X)\u001b[39m\n\u001b[32m    195\u001b[39m x_1 = np.ones((m,n +\u001b[32m1\u001b[39m ))\n\u001b[32m    196\u001b[39m x_1 [:,\u001b[32m1\u001b[39m:] = x_vif\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m theta = np.linalg.pinv(\u001b[43mX_1\u001b[49m.T @ X_1) @ X_1.T @ y_vif\n\u001b[32m    198\u001b[39m y_p = x_1 @ theta\n\u001b[32m    199\u001b[39m ssr = np.sum((y_vif - y_p)**\u001b[32m2\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_1' is not defined"
     ]
    }
   ],
   "source": [
    "# la funcion sigmoide\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "e = np.e\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def normalizacion(X):\n",
    "    n , m = X.shape\n",
    "    medias = np.zeros(m)\n",
    "    varianzas = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        medias[i] = X[:,i].mean()\n",
    "        varianzas[i] = X[:,i].std()\n",
    "    for i in range(m):\n",
    "        X[:,i] = (X[:,i] - medias[i])/varianzas[i]\n",
    "    return X\n",
    "\n",
    "def sigmoide(z):\n",
    "    return 1/(1 + e**(-z))\n",
    "    \n",
    "# el * es producto escalar implicito\n",
    "\n",
    "def coste_logistico(X,y,theta):\n",
    "    z = X @ theta\n",
    "    h_theta = sigmoide(z)\n",
    "    return -np.sum( y*np.log(h_theta) + (1- y )*np.log(1-p))/len(y)\n",
    "\n",
    "def gradiente_logistica_explicito(X,y,theta):\n",
    "    n, m = X.shape\n",
    "    grad = np.zeros(m)\n",
    "    for i in range(n):\n",
    "        zi = 0\n",
    "        for j in range(m):\n",
    "            zi +=X[i,j]*theta[j]\n",
    "        h_theta = sigmoide(zi)\n",
    "        for j in range(m):\n",
    "            grad[j] =grad[j] + (h_theta - y[i]) * X[i,j]\n",
    "    return grad/n\n",
    "    \n",
    "def gradiente_logistica(X,y,theta):\n",
    "    z = X @ theta\n",
    "    #print(f\"z :\\n{z}\")\n",
    "    h_theta = sigmoide(z)\n",
    "    #print(f\"h_theta\\n{h_theta}\")\n",
    "    #print(f\"X.t\\n{X.T}\") \n",
    "    #print(f\"h_theta-y \\n{h_theta - y}\")\n",
    "    #print(f\"delta theta \\n{X.T @ (h_theta - y)}\")\n",
    "    return X.T @ (h_theta - y)\n",
    "    \n",
    "# lo innesariamente irritante de numpy es que delta theta = gradiente_logistica\n",
    "# no es un vector columna (2,1) sino (2,)\n",
    "# porque colapsa dimensiones inncesarias que perdida de intuitividad\n",
    "# como sea se usa salida.reshape(-1,1) y se obtiene (2,1)\n",
    "   \n",
    "def descenso_gradiente_logistica(X,y,alpha=0.01,N=5000):\n",
    "    n , m = X.shape #m cantidad de predictores + 1\n",
    "    print(f\"n,m: {X.shape}\")\n",
    "    theta = np.zeros(m) \n",
    "    print(f\"theta\\n:{theta}\")\n",
    "    for _ in range(N):\n",
    "        z = X @ theta  \n",
    "        h_theta = sigmoide(z)\n",
    "        delta_theta = X.T @ (h_theta - y)\n",
    "        theta = theta - alpha * delta_theta\n",
    "    return theta\n",
    "\n",
    "def descenso_gradiente_logistica_L1(X,y,alpha=0.01,N=1000,lam=1):\n",
    "    n, m = X.shape\n",
    "    theta = np.zeros(m)\n",
    "    for _ in range(N):\n",
    "        z = X @ theta\n",
    "        h_theta = sigmoide(z)\n",
    "        grad = X.T @ (h_theta - y)\n",
    "        grad[0] = grad[0]/n\n",
    "        for j in range(1,m):\n",
    "            grad[j] = grad[j]/n + (lam/n)*np.sign(theta[j])\n",
    "        theta = theta - alpha * grad\n",
    "    return theta\n",
    "\n",
    "def descenso_gradiente_logistica_ElasticNet(X,y,alpha=0.01,N=1000,lam=1,r=0.5):\n",
    "    n , m = X.shape\n",
    "    theta = np.zeros(m)\n",
    "    for _ in range(N):\n",
    "        z = X @ theta\n",
    "        h_theta = sigmoide(z)\n",
    "        grad = (X.T @ (h_theta - y))/n\n",
    "        for j in range(1,m):\n",
    "            l1 = (lam/n) * np.sign(theta[j])\n",
    "            l2 = (lam/n) * theta[j]\n",
    "            grad[j] = grad[j] + r*l1 + (1-r)*l2\n",
    "        theta = theta - alpha * grad\n",
    "    return theta\n",
    "    \n",
    "def descenso_gradiente_logistica_L2(X,y,alpha=0.01,N=1000,lam =1):\n",
    "    n , m = X.shape \n",
    "    theta = np.zeros(m)\n",
    "    for _ in range(N):\n",
    "        z = X @ theta\n",
    "        h_theta = sigmoide(z)\n",
    "        grad = X.T @ (h_theta - y)\n",
    "        grad[0] = grad[0]/n\n",
    "        for j in range(1,m):\n",
    "            grad[j] = grad[j]/n + (lam/n)*theta[j]\n",
    "        theta = theta - alpha * grad\n",
    "    return theta\n",
    "    \n",
    "def entrenar(Xs,y):\n",
    "    m = None\n",
    "    X = None\n",
    "    if Xs.ndim == 1:\n",
    "        m = 2\n",
    "        Xs = (Xs -Xs.mean())/Xs.std()\n",
    "        X = np.ones((len(Xs),m))\n",
    "        X[:,1]=Xs\n",
    "        print(f\"X\\n{X}\")\n",
    "    else:\n",
    "        n , m = Xs.shape\n",
    "        Xs = normalizacion(Xs)\n",
    "        X = np.ones((n,m + 1))\n",
    "        X[:,1:] = Xs\n",
    "        print(f\"X\\n{X}\")\n",
    "    #theta_final = descenso_gradiente_logistica(X,y)\n",
    "    theta_final = descenso_gradiente_logistica_L2(X,y)\n",
    "    #theta_final = descenso_gradiente_logistica_L1(X,y)\n",
    "    #theta_final = descenso_gradiente_logistica_ElasticNet(X,y)\n",
    "    return theta_final\n",
    "\n",
    "# si theta1 es 1.14 e**theta1 es 3.14 por cada 1k extra de ingreso ,la\n",
    "#posibilidad de aceptar el prestamo se multplica por 3.14\n",
    "def odds_ratio(theta1_m):\n",
    "    odds_ratio = e**theta1_m\n",
    "    print(f\"Odds Ratio: {odds_ratio:.4f}\")\n",
    "    print(f\"Interpretación: Por cada unidad de ingreso extra, los 'Odds' de aceptar el préstamo suben un {(odds_ratio-1)*100:.2f}%\")\n",
    "    #¿Qué pasa si el ingreso de ese cliente sube en 10 unidades ($10k)?\n",
    "    #nuevo_odds = odss * (e**theta1)**10\n",
    "    p = 0.2\n",
    "    odds  = p/(1-p)\n",
    "    nuevos_odds = odds * (odds_ratio ** 10)\n",
    "    print(f\"Si el ingreso sube 10 unidades, los nuevos Odds son: {nuevos_odds:.4f}\")\n",
    "\n",
    "def calcular_tp(y_real,y_pred):\n",
    "    tp = 0\n",
    "    n = len(y_real)\n",
    "    for i in range(n):\n",
    "        if y_real[i] == 1 and y_pred[i] == 1:\n",
    "            tp +=1\n",
    "    return tp\n",
    "# pero dentro de evaluar_nodelo se hace en un linea    \n",
    "def evaluar_modelo(X,y_real,theta):\n",
    "    z = X @ theta\n",
    "    probs = sigmoide(z)\n",
    "    y_pred = (probs > 0.5).astype(int) #probs >0.5 ? y_pred = 1 : y_pred= 0\n",
    "    tp = np.sum((y_real == 1)&(y_pred == 1)) # verdaderos positivos\n",
    "    tn = np.sum((y_real == 0)&(y_pred == 0)) # verdaderos negativos\n",
    "    fp = np.sum((y_real == 0)&(y_pred == 1)) # falsos positivos\n",
    "    fn = np.sum((y_real == 1)&(y_pred == 0)) # falsos negativos\n",
    "    accuracy = (tp + tn)/len(y_real)\n",
    "    precision = tp/(tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp/(tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2*(precision * recall)/(precision + recall) if (precision + recall) > 0 else 0\n",
    "    return {\"matriz\":[[tn,fp],[fn,tp]],\n",
    "            \"accuracy\":accuracy,\n",
    "            \"precision\":precision,\n",
    "            \"recall\":recall,\n",
    "            \"f1\":f1}\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "def imprimir_metricas(metrics, nombres_clases=['-', '+']): \n",
    "    matriz = metrics['matriz']\n",
    "    df_matriz = pd.DataFrame(\n",
    "        matriz,\n",
    "        index=nombres_clases,\n",
    "        columns=['Pred 0', 'Pred 1']\n",
    "    )\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(df_matriz)\n",
    "    print() \n",
    "    print(\"Métricas del modelo:\")\n",
    "    for metrica in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "        valor = metrics[metrica]\n",
    "        print(f\"{metrica}: {valor:.4f}\")\n",
    "  \n",
    "\n",
    "def vif_(df_X):\n",
    "    cols = df_X.columns\n",
    "    vif = {}\n",
    "    X = df_X.values\n",
    "    for i,col in enumerate(cols):\n",
    "        y_vif = X[:,i]\n",
    "        x_vif = np.delete(X,i,axis=1)\n",
    "        m,n = x_vif.shape\n",
    "        X_1 = np.ones((m,n +1 ))\n",
    "        X_1 [:,1:] = x_vif\n",
    "        theta = np.linalg.pinv(X_1.T @ X_1) @ X_1.T @ y_vif\n",
    "        y_p = x_1 @ theta\n",
    "        ssr = np.sum((y_vif - y_p)**2)\n",
    "        sst = np.sum((y_vif - np.mean(y_vif))**2)\n",
    "        r2 = 1 -(ssr/sst)\n",
    "        vif[col] = 1/(1-r2)\n",
    "    return pd.Series(vif)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    data = {'Income': [40, 50, 60, 100, 150, 200],\n",
    "        'Accepted': [0, 0, 0, 1, 1, 1]}    \n",
    "    df = pd.DataFrame(data)\n",
    "    X = df['Income'].values\n",
    "    print(f\"{X} {X.shape}\")\n",
    "    y = df['Accepted'].values\n",
    "    print(y)\n",
    "    theta = entrenar(X,y)\n",
    "    print(f\"theta :\\n{theta}\")\n",
    "    odds_ratio(theta[1])\n",
    "    n , m = len(X), len(theta)\n",
    "    X_in = np.ones((n,m))\n",
    "    X_in[:,1] = (X - X.mean())/X.std()\n",
    "    metrics = evaluar_modelo(X_in,y,theta)\n",
    "    print(f\"metricas\\n{metrics}\")\n",
    "    df = pd.DataFrame(metrics['matriz'],index =['-','+'],columns=['N-','P+'])\n",
    "    print(df)\n",
    "    df_metrics = pd.DataFrame({\n",
    "    'Métrica': ['accuracy', 'precision', 'recall', 'f1'],\n",
    "    'Valor': [metrics['accuracy'], metrics['precision'], metrics['recall'], metrics['f1']]\n",
    "    })\n",
    "    print(df_metrics)\n",
    "    # con data real\n",
    "    datos = fetch_california_housing()\n",
    "    X = datos.data\n",
    "    y = datos.target\n",
    "    print(f\"VIF:\")\n",
    "    df_vif = pd.DataFrame(datos.data,columns=datos.feature_names)\n",
    "    analisis_vif = vif_(df_vif)\n",
    "    print(analisis_vif)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    umbral = np.median(y_train)\n",
    "    y_train = (y_train >= umbral).astype(int)\n",
    "    y_test = (y_test >= umbral).astype(int)\n",
    "    theta = entrenar(X_train,y_train)\n",
    "    X_test_norm = normalizacion(X_test)\n",
    "    n_test = X_test_norm.shape[0]\n",
    "    m = X_test_norm.shape[1]\n",
    "    X_test_input = np.ones((n_test, m + 1))\n",
    "    X_test_input[:,1:] = X_test_norm\n",
    "    metrics = evaluar_modelo(X_test_input, y_test, theta)\n",
    "    imprimir_metricas(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e7d1419-4522-4f06-9349-6606fda7e20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06570093]\n",
      "[[1.14589619]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# constrastando con  sklearn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = np.array([40, 50, 60, 100, 150, 200]).reshape(-1, 1)\n",
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "model = LogisticRegression(penalty='l2', C=1, fit_intercept=True, solver='lbfgs')\n",
    "model.fit(X_std, y)\n",
    "\n",
    "print(model.intercept_)\n",
    "print(model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8b670de-20cc-454f-a715-dfc21625ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta final: [-1.70974346e-16  1.19534012e-16]\n",
      "Theta (umbrales) final: [-0.69315197  0.69315197]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "e = np.e\n",
    "\n",
    "def sigmoide(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def normalizacion(X):\n",
    "    n, m = X.shape\n",
    "    medias = np.zeros(m)\n",
    "    varianzas = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        medias[i] = X[:,i].mean()\n",
    "        varianzas[i] = X[:,i].std()\n",
    "    for i in range(m):\n",
    "        X[:,i] = (X[:,i] - medias[i])/varianzas[i]\n",
    "    return X\n",
    "\n",
    "# --- Descenso de gradiente para logística ordinal ---\n",
    "def descenso_gradiente_ordinal(X, y, N=5000, alpha=0.01):\n",
    "    \"\"\"\n",
    "    X: matriz normalizada con columna de 1 al inicio\n",
    "    y: vector de etiquetas ordinales {0,1,2}\n",
    "    \"\"\"\n",
    "    n, m = X.shape\n",
    "    clases = np.unique(y)\n",
    "    K = len(clases)\n",
    "    \n",
    "    # Inicializar beta y umbrales theta (ordenados)\n",
    "    beta = np.zeros(m)\n",
    "    theta = np.linspace(-1, 1, K-1)  # θ1, θ2\n",
    "    \n",
    "    for _ in range(N):\n",
    "        # Gradientes\n",
    "        grad_beta = np.zeros(m)\n",
    "        grad_theta = np.zeros(K-1)\n",
    "        \n",
    "        for i in range(n):\n",
    "            xi = X[i]\n",
    "            yi = y[i]\n",
    "            \n",
    "            # Probabilidades acumuladas\n",
    "            p_cum = []\n",
    "            for k in range(K-1):\n",
    "                p = sigmoide(theta[k] - xi @ beta)\n",
    "                p_cum.append(p)\n",
    "            \n",
    "            # Probabilidades de cada clase\n",
    "            pY = np.zeros(K)\n",
    "            pY[0] = p_cum[0]\n",
    "            for k in range(1, K-1):\n",
    "                pY[k] = p_cum[k] - p_cum[k-1]\n",
    "            pY[K-1] = 1 - p_cum[K-2]\n",
    "            \n",
    "            # Gradiente log-verosimilitud (beta)\n",
    "            for k in range(K):\n",
    "                indicator = 1 if yi == k else 0\n",
    "                # Parcial de beta (sigmoide de cada umbral)\n",
    "                if k == 0:\n",
    "                    grad_beta += -(indicator - pY[k]) * xi\n",
    "                elif k == K-1:\n",
    "                    grad_beta += -(indicator - pY[k]) * xi\n",
    "                else:\n",
    "                    grad_beta += -(indicator - pY[k]) * xi\n",
    "            \n",
    "            # Gradiente log-verosimilitud (theta)\n",
    "            for k in range(K-1):\n",
    "                indicator = 1 if yi <= k else 0\n",
    "                grad_theta[k] += -(indicator - p_cum[k])\n",
    "        \n",
    "        # Actualización\n",
    "        beta -= alpha * grad_beta / n\n",
    "        theta -= alpha * grad_theta / n\n",
    "    \n",
    "    return beta, theta\n",
    "\n",
    "# --- Función de entrenamiento ---\n",
    "def entrenar_ordinal(Xs, y):\n",
    "    # Normalización\n",
    "    if Xs.ndim == 1:\n",
    "        Xs = (Xs - Xs.mean()) / Xs.std()\n",
    "        n = len(Xs)\n",
    "        m = 1\n",
    "        X = np.ones((n, m + 1))\n",
    "        X[:,1] = Xs\n",
    "    else:\n",
    "        n, m = Xs.shape\n",
    "        Xs = normalizacion(Xs)\n",
    "        X = np.ones((n, m + 1))\n",
    "        X[:,1:] = Xs\n",
    "\n",
    "    beta, theta = descenso_gradiente_ordinal(X, y)\n",
    "    return beta, theta\n",
    "    \n",
    "# --- Ejemplo ---\n",
    "if __name__=='__main__':\n",
    "    # Datos ordinales (0 < 1 < 2)\n",
    "    data = {'Income': [40, 50, 60, 100, 150, 200],\n",
    "            'Accepted': [0, 0, 1, 1, 2, 2]}\n",
    "    df = pd.DataFrame(data)\n",
    "    X = df[['Income']].values\n",
    "    y = df['Accepted'].values\n",
    "\n",
    "    beta, theta = entrenar_ordinal(X, y)\n",
    "    print(f\"Beta final: {beta}\")\n",
    "    print(f\"Theta (umbrales) final: {theta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4456868c-d5ea-47e1-9b19-1c6553f2d4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mord in c:\\users\\usuario\\anaconda3\\lib\\site-packages (0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Beta (coeficiente de X): [0.73110115]\n",
      "Theta (umbrales): [-0.17974828  0.17974831]\n",
      "y_pred\n",
      "[0 1 1 1 1 2]\n",
      "probs acumulada\n",
      "[[0.63444941 0.07872455 0.28682604]\n",
      " [0.45518353 0.08963294 0.45518352]\n",
      " [0.45518353 0.08963294 0.45518352]\n",
      " [0.45518353 0.08963294 0.45518352]\n",
      " [0.45518353 0.08963294 0.45518352]\n",
      " [0.28682605 0.07872455 0.6344494 ]]\n"
     ]
    }
   ],
   "source": [
    "# mord\n",
    "%pip install mord\n",
    "import mord as m\n",
    "\n",
    "def mord():\n",
    "    X = np.array([[40],[50],[60],[100],[150],[200]])\n",
    "    y = np.array([0, 0, 1, 1, 2, 2])\n",
    "    X_std = normalizacion(X)\n",
    "    logit_ord = m.LogisticIT(alpha = 1)\n",
    "    logit_ord.fit(X_std,y) \n",
    "    print(\"Beta (coeficiente de X):\", logit_ord.coef_) \n",
    "    print(\"Theta (umbrales):\", logit_ord.theta_)\n",
    "    y_pred = logit_ord.predict(X_std)\n",
    "    print(f\"y_pred\\n{y_pred}\")\n",
    "    probs = logit_ord.predict_proba(X_std)\n",
    "    print(f\"probs acumulada\\n{probs}\")\n",
    "    #probs_cum[i,0] = P(Y ≤ 0)\n",
    "    #probs_cum[i,1] = P(Y ≤ 1)\n",
    "    #P(Y=2) = 1 - P(Y ≤ 1)\n",
    "\n",
    "mord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31723bb7-3ebb-4342-bad2-234c8e9d3315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
