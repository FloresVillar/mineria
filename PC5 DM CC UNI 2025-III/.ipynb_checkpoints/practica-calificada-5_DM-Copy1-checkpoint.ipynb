{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a0e8b3-9da7-4145-867f-7aa825268a3c",
   "metadata": {},
   "source": [
    "# <img src=\"uni-logo.png\" alt=\"Logo UNI\" width=150 hight=300 align=\"right\">\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "<h1><font color=\"#7F000E\" size=4>Minería de Datos (CC442)</font></h1>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#7F000E\" size=6>Práctica Calificada V</font></h1>\n",
    "<h1><font color=\"#7F000E\" size=4>Fecha: 27/02/2026</font></h1>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#7F000E\" size=3>Facultad de Ciencias</font><br>\n",
    "<font color=\"#7F000E\" size=3>Ciencia de la Computación - UNI</font><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e09b27c-32fa-4063-aa17-3bfde94b98ee",
   "metadata": {},
   "source": [
    "\n",
    "### Ejercicio 1: Propensión de Compra con Redes Neuronales y Análisis de Elevación (10 puntos)\n",
    "\n",
    "#### Contexto Empresarial\n",
    "\n",
    "East–West Airlines se ha asociado con la compañía de telefonía móvil Telcon para vender sus servicios por correo directo. El archivo `EastWestAirlinesNN.csv` contiene un subconjunto de una muestra de datos de quienes ya han recibido una oferta de prueba.  East–West Airlines busca optimizar su campaña de marketing directo para contratos de telefonía. Solo el **13%** de los clientes acepta la oferta (`Phone_Sale = 1`). Debido al costo de enviar correos físicos, la empresa no puede contactar a todos; necesita priorizar a los clientes con mayor probabilidad de conversión.\n",
    "\n",
    "#### Instrucciones\n",
    "\n",
    "#### 1. Preprocesamiento Avanzado y Feature Engineering\n",
    "*   **Tratamiento de Variables:** Convierte variables categóricas en *dummies*. Escala todas las variables numéricas al rango [0, 1] usando `MinMaxScaler`.\n",
    "*   **Desequilibrio de Clases:** Dado que solo el 13% compró el servicio, explica por qué usar \"Accuracy\" como métrica principal sería un error en este caso. \n",
    "*   **Partición:** Divide los datos en **60% entrenamiento** y **40% validación**.\n",
    "\n",
    "#### 2. Arquitectura de la Red: El Impacto de la Complejidad\n",
    "Deberás comparar tres modelos de Redes Neuronales (MLPRegressor o MLPClassifier):\n",
    "1.  **Modelo A (Underfitting):** 1 capa oculta con **1 solo nodo**.\n",
    "2.  **Modelo B (Base):** 1 capa oculta con **5 nodos**.\n",
    "3.  **Modelo C (Deep & Regularized):** 2 capas ocultas con **(10, 5) nodos**, utilizando una penalización L2 ($\\alpha = 0.01$) para controlar el sobreajuste.\n",
    "\n",
    "#### 3. Evaluación Mediante Decile Lift Charts\n",
    "Para cada modelo, genera un **Decile Lift Chart** para el conjunto de validación.\n",
    "*   **Cálculo:** Ordena las predicciones de mayor a menor probabilidad, divide en 10 grupos (deciles) y calcula cuánto mejor es el modelo que el azar en cada decil.\n",
    "*   **Interpretación:** Explica el significado del primer decil (el de más a la izquierda) en términos de ahorro para el departamento de marketing.\n",
    "\n",
    "#### 4. Análisis de Overfitting y Generalización\n",
    "Compara los Lift Charts de entrenamiento vs. validación del **Modelo B** (5 nodos). \n",
    "*   Si la elevación en entrenamiento es de 4.5 en el primer decil, pero en validación es de 1.8, ¿qué puedes concluir sobre la capacidad de generalización del modelo?\n",
    "\n",
    "#### Preguntas del Ejercicio\n",
    "\n",
    "**a. (Interpretación de Negocio):** Si el primer decil del gráfico de elevación (lift) en validación tiene un valor de **3.5**, ¿qué significa esto para el director de marketing si decide enviar correos solo al 10% de los clientes con mayor puntaje?\n",
    "\n",
    "**b. (Comparación de Modelos):** ¿Cómo cambia la forma del Lift Chart al pasar de 1 nodo a 5 nodos? ¿Por qué el modelo de 1 nodo se comporta de forma similar a una Regresión Logística?\n",
    "\n",
    "**c. (Matemáticas de la Red):** Extrae los pesos (weights) del modelo con 1 nodo. ¿Qué información proporcionan estos pesos sobre la importancia de las variables? ¿Es posible interpretar los pesos del modelo de 10 nodos con la misma facilidad? Justifica tu respuesta.\n",
    "\n",
    "**d. (Criterio de Parada):** Durante el entrenamiento del modelo más complejo, observas que la pérdida (loss) en entrenamiento sigue bajando, pero la pérdida en validación empieza a subir tras 50 épocas. ¿Cómo se llama este fenómeno y qué técnica (además de la regularización L2) implementarías para detener el entrenamiento en el momento óptimo?\n",
    "\n",
    "### Código para el estudiante\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 1. Carga y preparación\n",
    "df = pd.read_csv(\"EastWestAirlinesNN.csv\")\n",
    "# Supongamos que Phone_Sale es el target\n",
    "X = df.drop(columns=['Phone_Sale'])\n",
    "y = df['Phone_Sale']\n",
    "\n",
    "# Crear Dummies y Escalar\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# 2. Entrenar Modelo B (5 nodos)\n",
    "mlp_b = MLPClassifier(hidden_layer_sizes=(5,), max_iter=1000, random_state=42)\n",
    "mlp_b.fit(X_train, y_train)\n",
    "\n",
    "# 3. Función para generar datos de Lift Chart (Concepto)\n",
    "def get_lift_data(model, X, y):\n",
    "    probs = model.predict_proba(X)[:, 1]\n",
    "    df_results = pd.DataFrame({'actual': y, 'prob': probs})\n",
    "    df_results = df_results.sort_values(by='prob', ascending=False)\n",
    "    # Dividir en 10 deciles y calcular lift...\n",
    "    # (El estudiante debe completar esta lógica)\n",
    "    return lift_values\n",
    "\n",
    "# --- El estudiante debe implementar el resto del análisis ---\n",
    "```\n",
    "\n",
    "---\n",
    "### Ejercicio 2: Predicción de Precios con K-NN y Optimización de Estructuras Espaciales (10 puntos)\n",
    "\n",
    "#### Contexto\n",
    "El dataset `BostonHousing.csv` contiene información de 506 áreas censales. El objetivo es predecir `MEDV` (valor mediano de la vivienda en $1000s).\n",
    "\n",
    "#### Requerimientos previos\n",
    "1.  Ignorar la columna `CAT.MEDV`.\n",
    "2.  Dividir los datos: **60% Entrenamiento** y **40% Validación**.\n",
    "3.  **Escalado:** Debes justificar y aplicar `StandardScaler` o `MinMaxScaler`.\n",
    "\n",
    "#### PARTE 1: Modelado y Optimización (Nivel Medio)\n",
    "\n",
    "**a. Selección de $k$ y Métrica de Distancia:**\n",
    "Realiza una búsqueda de hiperparámetros (Grid Search) para el modelo K-NN Regressor. Prueba valores de $k$ de 1 a 15 y dos métricas de distancia: **Euclidiana ($p=2$)** y **Manhattan ($p=1$)**.\n",
    "*   ¿Cuál es la combinación óptima de $k$ y métrica según el RMSE en el conjunto de validación?\n",
    "*   Explica: ¿Por qué un $k$ muy pequeño (ej. $k=1$) suele dar un error de entrenamiento de 0 pero un error de validación alto?\n",
    "\n",
    "**b. Predicción de Caso Específico:**\n",
    "Utilizando el mejor modelo encontrado, predice el `MEDV` para el siguiente sector:\n",
    "`CRIM: 0.2, ZN: 0, INDUS: 7, CHAS: 0, NOX: 0.538, RM: 6, AGE: 62, DIS: 4.7, RAD: 4, TAX: 307, PTRATIO: 21, LSTAT: 10`\n",
    "*   *Nota:* Recuerda aplicar la misma transformación de escalado que usaste en el entrenamiento.\n",
    "\n",
    "#### PARTE 2: Eficiencia y Estructuras de Datos (Nivel Avanzado)\n",
    "\n",
    "**c. Benchmarking de Algoritmos de Búsqueda:**\n",
    "Implementa el mejor modelo ($k$ óptimo) utilizando tres enfoques de búsqueda diferentes:\n",
    "1.  `algorithm='brute'` (Fuerza bruta).\n",
    "2.  `algorithm='kd_tree'` (KD-Tree).\n",
    "3.  `algorithm='ball_tree'` (Ball-Tree).\n",
    "\n",
    "*   **Pregunta técnica:** Mide el tiempo de ejecución de las predicciones en el set de validación para los tres. Si el dataset creciera a 1,000,000 de registros y 50 dimensiones (features), ¿cuál de estos algoritmos esperarías que fallara primero y por qué? (Menciona la \"Maldición de la Dimensionalidad\").\n",
    "\n",
    "**d. Análisis de la Hoja (Leaf Size):**\n",
    "Para el modelo con `kd_tree`, varía el parámetro `leaf_size` entre `[2, 30, 100, 500]`. \n",
    "*   ¿Cómo afecta el `leaf_size` al tiempo de respuesta?\n",
    "*   ¿Cambia el valor de la predicción final al cambiar el `leaf_size`? Justifica tu respuesta basada en el funcionamiento del algoritmo KD-Tree.\n",
    "\n",
    "#### PARTE 3: Teoría y Evaluación Crítica\n",
    "\n",
    "**e. Sesgo del Error de Validación:**\n",
    "¿Por qué el error obtenido en el conjunto de validación podría ser \"excesivamente optimista\" si utilizaste ese mismo conjunto para elegir el mejor valor de $k$? ¿Qué técnica (ej. Nested Cross-Validation) recomendarías para obtener una estimación más real del error en datos no vistos?\n",
    "\n",
    "**f. Desventajas Computacionales en Producción:**\n",
    "Imagina que debes predecir el precio de 10,000 nuevas casas cada segundo en un sistema de trading en tiempo real. \n",
    "1.  ¿Cuál es la principal desventaja de K-NN frente a una Regresión Lineal en términos de **almacenamiento de memoria**?\n",
    "2.  ¿Cuál es la desventaja en términos de **tiempo de cómputo (latencia)** durante la fase de predicción?\n",
    "3.  ¿Cómo ayuda un KD-Tree a mitigar esto y cuál es su límite?\n",
    "\n",
    "#### Código para el estudiante \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "##### 1. Carga y Limpieza\n",
    "df = pd.read_csv(\"BostonHousing.csv\")\n",
    "X = df.drop(columns=['MEDV', 'CAT.MEDV'])\n",
    "y = df['MEDV']\n",
    "\n",
    "##### 2. Partición\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "##### 3. Escalado (OBLIGATORIO)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "##### --- El estudiante debe continuar desde aquí ---\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
