{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa9e564-3c4d-47d7-bbbf-3e0ff36d3b27",
   "metadata": {},
   "source": [
    "# <img src=\"uni-logo.png\" alt=\"Logo UNI\" width=150 hight=300 align=\"right\">\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "<h1><font color=\"#7F000E\" size=4>Minería de Datos (CC442)</font></h1>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#7F000E\" size=6>Clustering</font></h1>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#7F000E\" size=3>Yuri Coicca, M.Sc.</font><br>\n",
    "<font color=\"#7F000E\" size=3>Facultad de Ciencias</font><br>\n",
    "<font color=\"#7F000E\" size=3>Ciencia de la Computación - UNI</font><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93101ab9-e251-4638-98d6-0b9e639e8ad7",
   "metadata": {},
   "source": [
    "El **clustering** (o agrupamiento) es una técnica de aprendizaje no supervisado que busca organizar datos en grupos (clústeres) de tal manera que los elementos dentro de un mismo grupo sean muy similares entre sí y muy diferentes a los de otros grupos.\n",
    "\n",
    "A continuación, te explico a detalle los tres tipos principales solicitados:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Clustering Basado en Centroides\n",
    "Es el tipo de agrupamiento más común y sencillo. En este enfoque, cada clúster se representa mediante un punto central llamado **centroide**.\n",
    "\n",
    "*   **Algoritmo principal:** **K-Means**.\n",
    "*   **Funcionamiento:**\n",
    "    1.  Se define de antemano el número de grupos ($K$).\n",
    "    2.  Se eligen $K$ puntos iniciales al azar (centroides iniciales).\n",
    "    3.  **Asignación:** Cada dato del conjunto se asigna al centroide más cercano (usualmente usando la distancia euclidiana).\n",
    "    4.  **Actualización:** Se recalcula la posición de cada centroide como el promedio (media) de todos los puntos asignados a él.\n",
    "    5.  Se repiten los pasos 3 y 4 hasta que los centroides dejen de moverse.\n",
    "\n",
    "*   **Ventajas:** Es extremadamente rápido y escalable para grandes conjuntos de datos.\n",
    "*   **Desventajas:** Tienes que saber el valor de $K$ de antemano. Es muy sensible a valores atípicos (outliers) y solo funciona bien si los grupos tienen forma esférica o circular.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Clustering Jerárquico\n",
    "Este método no busca una partición única, sino que crea una estructura de árbol llamada **dendrograma** que muestra cómo se agrupan los datos en diferentes niveles de similitud.\n",
    "\n",
    "*   **Tipos de enfoque:**\n",
    "    *   **Aglomerativo (Bottom-up):** Comienza con cada dato como un clúster individual y los va fusionando de dos en dos según su cercanía hasta que todos forman un solo gran grupo.\n",
    "    *   **Divisivo (Top-down):** Comienza con todos los datos en un solo grupo y los va dividiendo sucesivamente hasta que cada punto es su propio clúster.\n",
    "*   **Criterios de enlace (Linkage):** Para decidir qué grupos unir, se usan métricas como la distancia mínima entre puntos (enlace simple), distancia máxima (enlace completo) o el promedio.\n",
    "\n",
    "*   **Ventajas:** No requiere definir el número de clústeres al inicio; puedes \"cortar\" el dendrograma a la altura que desees para obtener el número de grupos ideal.\n",
    "*   **Desventajas:** Es computacionalmente muy costoso (lento para millones de datos) y, una vez que se ha realizado una unión o división, no se puede deshacer en pasos posteriores.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Clustering Basado en Densidades\n",
    "A diferencia de los anteriores, este método define los clústeres como regiones donde hay una \"alta densidad\" de puntos, separadas por regiones de \"baja densidad\".\n",
    "\n",
    "*   **Algoritmo principal:** **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise).\n",
    "*   **Conceptos clave:**\n",
    "    1.  **Epsilon ($\\epsilon$):** El radio máximo para buscar vecinos.\n",
    "    2.  **MinPts:** El número mínimo de puntos necesarios dentro de ese radio para considerar que una zona es \"densa\".\n",
    "    3.  **Puntos núcleo:** Puntos que tienen al menos `MinPts` vecinos.\n",
    "    4.  **Ruido:** Puntos que están en zonas de baja densidad y no pertenecen a ningún grupo.\n",
    "\n",
    "*   **Ventajas:** \n",
    "    *   Puede encontrar clústeres de **formas arbitrarias** (como lunas, anillos o formas alargadas) que K-Means no detectaría.\n",
    "    *   Detecta automáticamente el ruido/outliers.\n",
    "    *   No necesitas especificar el número de grupos.\n",
    "*   **Desventajas:** No funciona bien si los clústeres tienen densidades muy diferentes entre sí o si los datos tienen muchas dimensiones (maldición de la dimensionalidad).\n",
    "\n",
    "---\n",
    "\n",
    "### Resumen Comparativo\n",
    "\n",
    "| Característica | Basado en Centroides (K-Means) | Jerárquico (AGNES) | Basado en Densidad (DBSCAN) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Forma del clúster** | Esférica | Cualquiera | Formas complejas / arbitrarias |\n",
    "| **Nº de grupos** | Debe definirse antes ($K$) | Se elige tras ver el árbol | Se descubre automáticamente |\n",
    "| **Ruido / Outliers** | Muy sensible (los incluye) | Los incluye en el árbol | Los identifica y descarta |\n",
    "| **Velocidad** | Muy rápido | Lento en datos grandes | Velocidad media |\n",
    "| **Uso ideal** | Datos compactos y bien separados | Cuando quieres ver la jerarquía | Datos con formas irregulares y ruido |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
