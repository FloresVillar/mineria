{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9876c75-ca9e-42d0-bea7-acac93c5b690",
   "metadata": {},
   "source": [
    "# <img src=\"uni-logo.png\" alt=\"Logo UNI\" width=150 hight=300 align=\"right\">\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "<h1><font color=\"#7F000E\" size=4>Data Mining (CC442)</font></h1>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#7F000E\" size=6>Variable Selection in Linear Regression</font></h1>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#7F000E\" size=3>Yuri Coicca, M.Sc.</font><br>\n",
    "<font color=\"#7F000E\" size=3>Faculty of Science</font><br>\n",
    "<font color=\"#7F000E\" size=3>Computer Science - UNI</font><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661ba1c-d232-4d10-a712-496a4f138706",
   "metadata": {},
   "source": [
    "**<H2>Variable Selection in Linear Regression**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Reducing the Number of Predictors (Reducción del número de predictores)\n",
    "Aunque hoy en día las computadoras pueden procesar modelos con muchísimas variables (el enfoque \"kitchen-sink\" o de \"todo a la vez\"), el texto advierte que esto es peligroso por varias razones:\n",
    "\n",
    "*   **Costo y Factibilidad:** Recolectar datos para muchas variables es caro y difícil en el futuro.\n",
    "*   **Calidad de los datos:** A más variables, mayor probabilidad de tener valores faltantes (missing values).\n",
    "*   **Parsimonia (Simplicidad):** Los modelos simples son más fáciles de explicar y entender.\n",
    "*   **Multicolinealidad:** Demasiadas variables suelen estar correlacionadas entre sí, lo que hace que los coeficientes de la regresión sean inestables.\n",
    "*   **Trade-off Sesgo-Varianza (Bias-Variance):**\n",
    "    *   Si añades variables irrelevantes, aumenta la **varianza** del modelo (el modelo se vuelve muy sensible a cambios en los datos de entrenamiento).\n",
    "    *   Si quitas variables importantes, aumenta el **sesgo** (el modelo es demasiado simple y no captura la realidad).\n",
    "    *   **La meta:** Encontrar el equilibrio que minimice el error total.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. How to Reduce the Number of Predictors (Cómo reducirlos)\n",
    "El primer paso no es matemático, sino de **conocimiento del negocio (Domain Knowledge)**.\n",
    "*   **Eliminación manual:** Se deben descartar variables que sean costosas de medir, que tengan muchos errores, que estén muy correlacionadas entre sí o que simplemente no tengan sentido lógico para el problema.\n",
    "*   **Herramientas estadísticas iniciales:** Usar tablas de correlación y gráficos para identificar qué variables no aportan información nueva.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Exhaustive Search (Búsqueda Exhaustiva)\n",
    "Este es el método \"fuerza bruta\". Consiste en evaluar **todas las combinaciones posibles** de predictores.\n",
    "\n",
    "**¿Cómo funciona?**\n",
    "Si tienes $p$ variables, el algoritmo prueba modelos con 1 variable, luego todas las parejas posibles, luego todos los tríos, y así hasta llegar al modelo con las $p$ variables.\n",
    "\n",
    "**Criterios de evaluación:**\n",
    "Como no podemos usar el $R^2$ normal (porque siempre sube al añadir variables, aunque sean basura), usamos métricas que **penalizan la complejidad**:\n",
    "\n",
    "1.  **Adjusted $R^2$ (R-cuadrado ajustado):** Penaliza al modelo por cada predictor extra. Un valor más alto es mejor. Maximizar el $R^2_{adj}$ es equivalente a minimizar el error cuadrático medio (RMSE).\n",
    "2.  **AIC (Akaike Information Criterion):** Estima el error de predicción. Penaliza el número de parámetros. **Buscamos el valor más bajo.**\n",
    "3.  **BIC (Bayesian Information Criterion):** Similar al AIC, pero la penalización por cada variable extra es más fuerte. **Buscamos el valor más bajo.**\n",
    "\n",
    "**Punto clave:** Si comparas modelos que tienen el **mismo número de variables**, todas estas métricas coincidirán en cuál es el mejor. La diferencia aparece cuando comparas un modelo de 3 variables contra uno de 5.\n",
    "\n",
    "En la búsqueda exhaustiva, el problema es que no podemos usar el $R^2$ normal para comparar modelos de diferentes tamaños, porque el $R^2$ tiene un \"vicio\": **siempre sube** cuando añades una variable, aunque sea una variable basura (como el color de los calcetines del conductor para predecir el precio de un carro).\n",
    "\n",
    "Para solucionar esto, el libro **Data Mining for Business Analytics** en la página 220 presenta tres ecuaciones \"jueces\" que penalizan el exceso de variables. Aquí te las explico al detalle:\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.1. R-Cuadrado Ajustado ($R^2_{adj}$)\n",
    "\n",
    "Es la versión \"honesta\" del $R^2$. La fórmula que aparece es:\n",
    "\n",
    "$$R^2_{adj} = 1 - \\frac{n-1}{n-p-1}(1 - R^2)$$\n",
    "\n",
    "*   **¿Qué significan las letras?**\n",
    "    *   $n$: Número de registros (filas de datos).\n",
    "    *   $p$: Número de predictores (variables).\n",
    "    *   $R^2$: El coeficiente de determinación normal.\n",
    "*   **¿Cómo funciona la \"trampa\"?** Mira la fracción $\\frac{n-1}{n-p-1}$. A medida que añades más variables ($p$ aumenta), el denominador ($n-p-1$) se hace más pequeño. Esto hace que toda la fracción sea más grande, lo que termina \"restando\" más valor al resultado final.\n",
    "*   **Conclusión:** El $R^2_{adj}$ solo subirá si la nueva variable ayuda tanto que compensa el \"castigo\" de haberla incluido. **Buscamos el valor más alto.**\n",
    "\n",
    "---\n",
    "\n",
    "#### 3,2. AIC (Akaike Information Criterion)\n",
    "\n",
    "Esta métrica viene de la teoría de la información y busca el modelo que menos información pierda. La fórmula es:\n",
    "\n",
    "$$AIC = n \\ln(SSE/n) + n(1 + \\ln(2\\pi)) + 2(p+1)$$\n",
    "\n",
    "*   **¿Cómo se lee?** Tiene dos partes en una pelea:\n",
    "    1.  **La precisión ($n \\ln(SSE/n)$):** Si el error ($SSE$) es pequeño, este número es bajo. Esto premia que el modelo le atine a los datos.\n",
    "    2.  **La penalización ($2(p+1)$):** Aquí es donde se castiga la complejidad. Por cada variable extra ($p$), el AIC sube.\n",
    "*   **Conclusión:** El AIC busca un equilibrio. **Buscamos el valor más bajo.** Se dice que el AIC es mejor para modelos que deben predecir muy bien, aunque sean un poco más complejos.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.3. BIC (Bayesian Information Criterion)\n",
    "\n",
    "También llamado Criterio de Schwartz. Es muy parecido al AIC, pero más \"estricto\":\n",
    "\n",
    "$$BIC = n \\ln(SSE/n) + n(1 + \\ln(2\\pi)) + \\ln(n)(p+1)$$\n",
    "\n",
    "*   **La diferencia clave:** Nota que en lugar de un $2$ (como en el AIC), aquí el castigo es **$\\ln(n)$**.\n",
    "*   **¿Por qué importa?** Si tienes muchos datos ($n$ es grande), el $\\ln(n)$ será mucho mayor que $2$. Esto significa que el BIC castiga las variables extra mucho más fuerte que el AIC.\n",
    "*   **Conclusión:** El BIC prefiere modelos más simples y pequeños (más parsimoniosos). **Buscamos el valor más bajo.**\n",
    "\n",
    "---\n",
    "\n",
    "### Resumen comparativo (Muy importante para tu explicación)\n",
    "\n",
    "El PDF menciona un punto vital al final de la página 3: \n",
    "\n",
    "> *\"Para un tamaño fijo de subconjunto, $R^2$, $R^2_{adj}$, AIC y BIC todos seleccionan el mismo subconjunto\"*.\n",
    "\n",
    "**¿Qué significa esto?** \n",
    "Si obligamos al algoritmo a buscar solo modelos de **3 variables**, todas las ecuaciones coincidirán en cuál es el mejor grupo de 3. \n",
    "\n",
    "La \"pelea\" entre las ecuaciones ocurre cuando el algoritmo debe decidir: **\"¿Es mejor este modelo de 3 variables o este otro de 6?\"**. \n",
    "*   El **AIC** podría decirte que el de 6 es mejor si la precisión aumenta un poco.\n",
    "*   El **BIC** probablemente te dirá que te quedes con el de 3 porque es más tacaño con el número de variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439235d0-36a9-4163-be01-b06a04c50ff2",
   "metadata": {},
   "source": [
    "### Acerca de la librería mlxtend \n",
    "---\n",
    "La librería **`mlxtend`** (abreviatura de **Machine Learning Extensions**) es una biblioteca de Python extremadamente útil que funciona como una \"caja de herramientas\" adicional para los científicos de datos.\n",
    "\n",
    "Su creador es Sebastian Raschka (un referente muy importante en el mundo del Machine Learning) y su objetivo principal es **complementar a Scikit-learn** con funciones que esa librería estándar no tiene.\n",
    "\n",
    "Aquí te detallo por qué es tan relevante, especialmente para lo que estás estudiando ahora:\n",
    "\n",
    "#### 1. Selección de Variables \n",
    "Esta es la joya de la corona de `mlxtend` para tu estudio actual. Mientras que Scikit-learn es un poco limitado en métodos automáticos de selección de \"subconjuntos\", `mlxtend` ofrece:\n",
    "*   **ExhaustiveFeatureSelector (EFS):** Lo que me pediste. Prueba literalmente todas las combinaciones posibles.\n",
    "*   **SequentialFeatureSelector (SFS):** Implementa el *Forward Selection* y *Backward Elimination* que mencionaba tu PDF de forma muy sencilla y visual.\n",
    "\n",
    "#### 2. Visualización de Modelos\n",
    "Tiene herramientas de graficación increíbles que Scikit-learn no incluye de forma nativa. Por ejemplo, te permite dibujar las **\"Regiones de Decisión\"**, que son mapas de calor que muestran cómo un modelo está clasificando los datos en un plano 2D. Es muy útil para entender si tu modelo está haciendo *overfitting* (sobreajuste).\n",
    "\n",
    "#### 3. Reglas de Asociación (Data Mining)\n",
    "Si alguna vez necesitas hacer análisis de \"canasta de compras\" (como el ejemplo de los protectores de patas de sillas y el riesgo crediticio que menciona tu PDF en la página 1), `mlxtend` es la librería líder. Incluye algoritmos como:\n",
    "*   **Apriori:** Para encontrar patrones de productos que se compran juntos.\n",
    "*   **Association Rules:** Para calcular la confianza y el soporte de esas relaciones.\n",
    "\n",
    "#### 4. Evaluación de Modelos\n",
    "Ofrece pruebas estadísticas más avanzadas que las de Scikit-learn, como:\n",
    "*   **Test de McNemar:** Para comparar si un algoritmo es estadísticamente mejor que otro.\n",
    "*   **Bias-Variance Decomposition:** Te permite medir exactamente cuánto error viene del \"Sesgo\" y cuánto de la \"Varianza\" (el famoso *trade-off* que menciona tu PDF en la página 2).\n",
    "\n",
    "#### 5. Ensambles de Modelos (Ensemble Methods)\n",
    "Permite hacer **Stacking**, que es una técnica avanzada donde usas un modelo de Machine Learning para \"aprender\" de las predicciones de otros modelos previos y así mejorar la precisión final.\n",
    "\n",
    "---\n",
    "\n",
    "#### ¿Por qué la usamos en el curso?\n",
    "*\"Because Python does not have an exhaustive search routine, we created a loop...\"*. \n",
    "\n",
    "Se tendría que programar un bucle manual. Sin embargo, con `mlxtend`, **no tienes que reinventar la rueda**. Esa librería ya tiene ese bucle optimizado, probado y listo para usarse con una sola línea de código, devolviéndote métricas detalladas de cada combinación de variables.\n",
    "\n",
    "**En resumen:** `mlxtend` es el puente entre el aprendizaje automático básico y el análisis estadístico profundo que necesitas para la selección de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf84c232-fd02-4363-884c-f0b48c508db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6802b351-2894-4db7-aea0-bb63285abb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0ab2b7a-c135-42d4-bfcb-d527ebb3f2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta de Python: C:\\Users\\YURI\\anaconda3\\python.exe\n",
      "✅ mlxtend detectada con éxito. Versión: 0.24.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Esto te dirá dónde está buscando Python las librerías\n",
    "print(\"Ruta de Python:\", sys.executable)\n",
    "\n",
    "try:\n",
    "    import mlxtend\n",
    "    print(\"✅ mlxtend detectada con éxito. Versión:\", mlxtend.__version__)\n",
    "except ImportError:\n",
    "    print(\"❌ mlxtend sigue sin aparecer en este entorno.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d653df75-854c-4687-b06c-7c8a7ee50f5c",
   "metadata": {},
   "source": [
    "### Ejemplo en Código (Python)\n",
    "Dado que Python (scikit-learn) no tiene una función nativa de \"Exhaustive Search\" como otros programas (ej. R), el texto menciona que se suele crear un bucle. Aquí te comparto un ejemplo funcional usando la librería `mlxtend`, que es el estándar para esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ea3fd0-12e5-43ea-b9d2-089c0bc1f004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 385/385"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor puntuación (R2): 0.47\n",
      "Mejores variables: ('bmi', 'bp', 's3', 's5')\n",
      "      feature_idx avg_score\n",
      "325  (2, 3, 6, 8)  0.472286\n",
      "318  (2, 3, 4, 8)  0.471379\n",
      "263  (1, 2, 3, 8)  0.466818\n",
      "123     (2, 3, 8)  0.462661\n",
      "322  (2, 3, 5, 8)  0.461128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "# 1. Cargar datos de ejemplo (Predicción de progresión de diabetes)\n",
    "diabetes = load_diabetes()\n",
    "X = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "y = diabetes.target\n",
    "\n",
    "# 2. Configurar la Búsqueda Exhaustiva\n",
    "# Queremos que pruebe combinaciones de entre 1 y 4 variables\n",
    "lr = LinearRegression()\n",
    "efs = EFS(lr, \n",
    "          min_features=1, \n",
    "          max_features=4, \n",
    "          scoring='r2', # Evaluamos basado en R-cuadrado\n",
    "          print_progress=True,\n",
    "          cv=5) # Validación cruzada para evitar overfitting\n",
    "\n",
    "# 3. Ejecutar la búsqueda\n",
    "efs = efs.fit(X, y)\n",
    "\n",
    "# 4. Resultados\n",
    "print('Mejor puntuación (R2): %.2f' % efs.best_score_)\n",
    "print('Mejores variables:', efs.best_feature_names_)\n",
    "\n",
    "# Podemos ver el detalle de todos los modelos probados\n",
    "df_results = pd.DataFrame.from_dict(efs.get_metric_dict()).T\n",
    "print(df_results[['feature_idx', 'avg_score']].sort_values('avg_score', ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77acd541-5ceb-4720-ac4c-2c688a82fa39",
   "metadata": {},
   "source": [
    "\n",
    "### Explicación del ejemplo\n",
    "---\n",
    "1.  **`EFS`**: Este objeto genera todas las combinaciones posibles (si pides de 1 a 4 variables entre 10 disponibles, probará cientos de modelos).\n",
    "2.  **`scoring='r2'`**: Aunque el $R^2$ normal es engañoso, al usar **validación cruzada (`cv=5`)**, estamos obligando al modelo a demostrar que esas variables funcionan en datos no vistos, lo cual actúa como una penalización natural similar al $R^2$ ajustado.\n",
    "3.  **Limitación:** Si tuvieras 100 variables, el Exhaustive Search tardaría años en terminar. Por eso, para muchos predictores, se usan los algoritmos que siguen en el texto: *Forward Selection* o *Backward Elimination*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef63403-9347-43aa-87e6-4589cdd0591d",
   "metadata": {},
   "source": [
    "### Explicación de los resultados\n",
    "---\n",
    "Estos resultados son la prueba real de lo que explica la sección **6.4 del libro del cursoF**. Aquí de tiene la interpretación detallada para que la uses en tu explicación:\n",
    "\n",
    "#### 1. El Ganador: La combinación óptima\n",
    "El algoritmo nos dice que el \"mejor\" modelo posible (dentro de lo que buscamos) tiene un **$R^2$ de 0.47** (aproximadamente 47%). Las variables elegidas son:\n",
    "*   **'bmi'** (Índice de masa corporal)\n",
    "*   **'bp'** (Presión sanguínea)\n",
    "*   **'s3'** y **'s5'** (Indicadores de suero sanguíneo)\n",
    "\n",
    "**Interpretación técnica:** Esto significa que con solo estas 4 variables, puedes explicar el 47% de la variación en la progresión de la enfermedad. Según el PDF, este es tu modelo \"parsimonioso\".\n",
    "\n",
    "#### 2. \"Features: 385/385\" (El esfuerzo exhaustivo)\n",
    "Este número es clave. Significa que el código probó **385 combinaciones diferentes** de variables.\n",
    "*   Probó todas las variables solas, todas las parejas posibles, todos los tríos y todos los grupos de cuatro.\n",
    "*   **Conexión con el PDF:** Esto es exactamente el **Exhaustive Search** que describe la página 3. No dejó ninguna piedra sin mover para encontrar ese 0.47.\n",
    "\n",
    "#### 3. Las variables \"Estrella\" (Análisis de los índices)\n",
    "Si miras la columna `feature_idx`, notarás un patrón muy interesante:\n",
    "*   El modelo #325 (el mejor) usa los índices **(2, 3, 6, 8)**.\n",
    "*   El modelo #123 (el cuarto mejor) usa **(2, 3, 8)**.\n",
    "\n",
    "**¿Qué significa esto?** Que las variables en las posiciones **2, 3 y 8** son extremadamente poderosas. Nota que el modelo #123, con solo **3 variables**, logra un puntaje de **0.462**, que es casi tan bueno como el mejor de 4 variables (0.472).\n",
    "\n",
    "#### 4. Relación con la \"Parsimonia\" (Sección 6.4 del libro)\n",
    "Aquí es donde puedes brillar en tu explicación:\n",
    "*   El PDF dice que \"a veces es mejor un modelo con menos variables si la diferencia en error es pequeña\".\n",
    "*   En tus resultados, pasar de 3 variables (score 0.462) a 4 variables (score 0.472) solo mejora el modelo en un **1%**. \n",
    "*   **Tu decisión como analista:** Podrías elegir el modelo de 3 variables porque es más simple, más barato de medir en el futuro y menos propenso a errores, cumpliendo con el principio de **Reducing the Number of Predictors**.\n",
    "\n",
    "#### 5. ¿Qué es el `avg_score`?\n",
    "En `mlxtend`, ese valor es el promedio del $R^2$ tras hacer validación cruzada. \n",
    "*   **Por qué es mejor que el R2 normal:** Porque asegura que ese 0.47 no es casualidad o \"suerte\" con unos pocos datos, sino que el modelo es robusto. Esto se relaciona con lo que dice el PDF en la página 3 sobre evitar el **Over-fitting** (ajustarse al ruido).\n",
    "\n",
    "**Resumen para tu presentación:**\n",
    "*\"Corrimos una búsqueda exhaustiva que evaluó 385 modelos. Encontramos que un subconjunto de 4 variables es el óptimo, pero identificamos que con solo 3 variables clave (índices 2, 3 y 8) obtenemos un rendimiento casi idéntico, lo cual nos permite tener un modelo más simple y parsimonioso como recomienda el texto.\"*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
