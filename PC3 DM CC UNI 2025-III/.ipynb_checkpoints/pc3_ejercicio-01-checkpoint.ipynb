{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94861717-bc70-4b7a-8aaf-821089137692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis VIF previo:\n",
      "mean radius         1460.924793\n",
      "mean texture           1.144166\n",
      "mean perimeter      1737.092968\n",
      "mean area             44.049377\n",
      "mean smoothness        2.064559\n",
      "mean compactness      11.866719\n",
      "dtype: float64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.159583\n",
      "         Iterations 10\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  455\n",
      "Model:                          Logit   Df Residuals:                      448\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Fri, 30 Jan 2026   Pseudo R-squ.:                  0.7581\n",
      "Time:                        10:35:44   Log-Likelihood:                -72.610\n",
      "converged:                       True   LL-Null:                       -300.17\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.887e-95\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const               -0.2118      0.513     -0.413      0.680      -1.218       0.794\n",
      "mean radius         22.7227     11.519      1.973      0.049       0.146      45.299\n",
      "mean texture        -1.5245      0.270     -5.650      0.000      -2.053      -0.996\n",
      "mean perimeter     -16.9275     11.091     -1.526      0.127     -38.666       4.811\n",
      "mean area          -12.6925      5.123     -2.477      0.013     -22.734      -2.651\n",
      "mean smoothness     -1.6533      0.360     -4.599      0.000      -2.358      -0.949\n",
      "mean compactness     0.2830      0.818      0.346      0.729      -1.321       1.887\n",
      "====================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.15 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        43\n",
      "           1       0.94      0.96      0.95        71\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "\n",
      "Odds Ratios:\n",
      "const               8.091427e-01\n",
      "mean radius         7.384681e+09\n",
      "mean texture        2.177343e-01\n",
      "mean perimeter      4.451362e-08\n",
      "mean area           3.074193e-06\n",
      "mean smoothness     1.914087e-01\n",
      "mean compactness    1.327105e+00\n",
      "dtype: float64\n",
      "PREGUNTAS DE REFLEXION\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "data = load_breast_cancer()                                             # 1. Cargar el dataset de scikit-learn\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)                # 2. Preprocesamiento , se seleccionan 6 columnas\n",
    "features = ['mean radius', 'mean texture', 'mean perimeter', \n",
    "            'mean area', 'mean smoothness', 'mean compactness']\n",
    "X = df[features]\n",
    "y = data.target                 # 1: Benigno, 0: Maligno  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)  # 3. Dividiendo en X_train,X_test,y_train,y_test \n",
    "u = X_train.mean()\n",
    "s = X_train.std()\n",
    "X_train_norm = (X_train - u) / s                                         # 4 . Escalamos , (x- media)/desviacion\n",
    "X_test_norm = (X_test - u) / s \n",
    "def calcular_vif(df_input):                                              # 5. Analisis VIF \n",
    "    vifs = {}\n",
    "    X_mat = df_input.values\n",
    "    for i, col in enumerate(df_input.columns):\n",
    "        y_temp = X_mat[:, i]\n",
    "        X_temp = np.delete(X_mat, i, axis=1)\n",
    "        X_temp = sm.add_constant(X_temp)\n",
    "        res = sm.OLS(y_temp, X_temp).fit()\n",
    "        vifs[col] = 1 / (1 - res.rsquared)\n",
    "    return pd.Series(vifs)\n",
    "print(\"Análisis VIF previo:\")\n",
    "print(calcular_vif(X_train_norm))    \n",
    "X_train_sm = sm.add_constant(X_train_norm)                               # 6. Construccion del modelo\n",
    "model = sm.Logit(y_train, X_train_sm)                                    # theta \n",
    "result = model.fit()                                                     # Ajuste Newton-Raphson\n",
    "print(result.summary())                                                  # 7. Resultados estadisticos\n",
    "X_test_sm = sm.add_constant(X_test_norm)                                 #  8. Evaluando con datos de prueba X_test normalizado\n",
    "probs = result.predict(X_test_sm)\n",
    "y_pred = (probs >= 0.5).astype(int)                                      # El umbral es 0.5 \n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))                             # Reporte de clasificacion\n",
    "# Odds Ratios\n",
    "odds_ratios = np.exp(result.params)                                      # 9. Intrepretacion de Coeficientes (Odds Ratios)\n",
    "print(\"\\nOdds Ratios:\")\n",
    "print(odds_ratios)\n",
    "print(f\"PREGUNTAS DE REFLEXION\\n\")\n",
    "#. sabemos que p-valor (P>∣z∣) ,Es la probabilidad de que el coeficiente sea realmente cero (es decir, que la variable no aporte ).\n",
    "# Si p-valor < 0.05: Rechazamos la idea de que la variable no aporta. Todo lo contrario es <estadísticamente significativa>.\n",
    "# Si p-valor > 0.05:No tenemos pruebas suficientes para decir que esa variable ayuda al modelo, posiblemente porque el VIF es muy alto y otra variable \n",
    "# le está robando su importancia.\n",
    "# De modo que segun el grafico en la columna P>|z|, los preedictores con p<0.05 son MEAN TEXTURE y MEAN SMOOTHNESS\n",
    "# los cuales son los mas significativos, también mean area y raidus en cierta medida\\n\\n\")\n",
    "\n",
    "#. VIF indica que los predictores RADIO y PERIMETRO están tan correlacionadas entre sí que el modelo no puede distinguir el efecto individual \n",
    "# de cada una., lo cual es obvio pues el perimetro se calcula usando el radio, de modo que MEAN RADIUS \n",
    "# tiene un VIF muy alto pues las variables como area y permitro dependen de ella\n",
    "\n",
    "# . \"El Coeficiente (theta): Es el cambio en el <logaritmo de la oportunidad> (log-odds =  log(p/(1- p)).\n",
    "# Si es positivo, aumenta la probabilidad de ser Benigno (clase 1).Si es negativo, aumenta la probabilidad de ser Maligno (clase 0).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209fed5-dc4f-4437-8b05-b17e676384df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9601206-eb87-4871-953d-030b31d39f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "a = np.arange(0,5,1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d156ba46-c6a1-4c09-87de-e8ef631988a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "[[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 1.326e+03 8.474e-02 7.864e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 1.203e+03 1.096e-01 1.599e-01]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 8.581e+02 8.455e-02 1.023e-01]\n",
      " [2.060e+01 2.933e+01 1.401e+02 1.265e+03 1.178e-01 2.770e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 1.810e+02 5.263e-02 4.362e-02]]\n",
      "y\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "569 , 455\n",
      "mean radius         1337.142105\n",
      "mean texture           1.188598\n",
      "mean perimeter      1590.170079\n",
      "mean area             49.378585\n",
      "mean smoothness        1.951526\n",
      "mean compactness      11.748830\n",
      "dtype: float64\n",
      "theta:\n",
      "[ 0.4943824  -0.77788118 -0.57973783 -0.79326192 -0.76770692 -0.44034087\n",
      " -0.63933108]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random as rd\n",
    "\n",
    "\n",
    " \n",
    "def separar_datos(X,y,p_): # l 8 columnas , n_sub 5 predictores\n",
    "    f = []\n",
    "    k,_ = X.shape\n",
    "    l = np.arange(0,k,1)\n",
    "    print(f\"{k} , {int((1-p_)*k)}\")\n",
    "    while k>1:\n",
    "        i = math.floor(k*rd.uniform(0,1))\n",
    "        #print(f\"i : {i}\")\n",
    "        l[k-1] , l[i] = l[i] , l[k-1]\n",
    "        f.append(l[k-1])\n",
    "        if (len(l) - k) + 1  == int((1-p_)*X.shape[0]):\n",
    "            break\n",
    "        k = k - 1\n",
    "    X_train = np.zeros((len(f),X.shape[1]))\n",
    "    y_train = np.zeros(len(f))\n",
    "    for i in range(len(f)):\n",
    "        X_train[i] = X[f[i]]\n",
    "        y_train[i] = y[f[i]]\n",
    "    resto = [i for i in l if i not in f]\n",
    "    X_test = np.zeros((len(resto),X.shape[1]))\n",
    "    y_test = np.zeros(len(resto))\n",
    "    for i in range(len(resto)):\n",
    "        X_test[i] = X[resto[i]]\n",
    "        y_test[i] = y[resto[i]]\n",
    "    return X_train,X_test,y_train,y_test\n",
    "    \n",
    "def sigmoide(z):\n",
    "    e = np.e\n",
    "    return 1/(1 + e**(-z))\n",
    "\n",
    "def gradiente_logistica(X,y,theta):\n",
    "    z = X @ theta\n",
    "    #print(f\"z :\\n{z}\")\n",
    "    h_theta = sigmoide(z) \n",
    "    return X.T @ (h_theta - y)\n",
    "\n",
    "def descenso_gradiente_logistica_L2(X,y,alpha=0.01,N=1000,lam =1):\n",
    "    n , m = X.shape \n",
    "    theta = np.zeros(m)\n",
    "    for _ in range(N):\n",
    "        z = X @ theta\n",
    "        h_theta = sigmoide(z)\n",
    "        grad = X.T @ (h_theta - y)\n",
    "        grad[0] = grad[0]/n\n",
    "        for j in range(1,m):\n",
    "            grad[j] = grad[j]/n + (lam/n)*theta[j]\n",
    "        theta = theta - alpha * grad\n",
    "    return theta\n",
    "\n",
    "#H=XTWX  \n",
    "#Wi=pi(1−pi)   con pi=σ(Xiθ)\n",
    "#θnew=θ+(XTWX)−1XT(y−p)\n",
    "\n",
    "def evaluar_modelo(X,y_real,theta):\n",
    "    z = X @ theta\n",
    "    probs = sigmoide(z)\n",
    "    y_pred = (probs > 0.5).astype(int) #probs >0.5 ? y_pred = 1 : y_pred= 0\n",
    "    tp = np.sum((y_real == 1)&(y_pred == 1)) # verdaderos positivos\n",
    "    tn = np.sum((y_real == 0)&(y_pred == 0)) # verdaderos negativos\n",
    "    fp = np.sum((y_real == 0)&(y_pred == 1)) # falsos positivos\n",
    "    fn = np.sum((y_real == 1)&(y_pred == 0)) # falsos negativos\n",
    "    accuracy = (tp + tn)/len(y_real)\n",
    "    precision = tp/(tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp/(tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2*(precision * recall)/(precision + recall) if (precision + recall) > 0 else 0\n",
    "    return {\"matriz\":[[tn,fp],[fn,tp]],\n",
    "            \"accuracy\":accuracy,\n",
    "            \"precision\":precision,\n",
    "            \"recall\":recall,\n",
    "            \"f1\":f1}\n",
    "\n",
    "\n",
    "def imprimir_metricas(metrics, nombres_clases=['-', '+']): \n",
    "    matriz = metrics['matriz']\n",
    "    df_matriz = pd.DataFrame(\n",
    "        matriz,\n",
    "        index=nombres_clases,\n",
    "        columns=['Pred 0', 'Pred 1']\n",
    "    )\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(df_matriz)\n",
    "    print() \n",
    "    print(\"Métricas del modelo:\")\n",
    "    for metrica in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "        valor = metrics[metrica]\n",
    "        print(f\"{metrica}: {valor:.4f}\")\n",
    "\n",
    "\n",
    "def vif_(X_):\n",
    "    cols = X_.columns\n",
    "    vif = {}\n",
    "    X_ = X_.values\n",
    "    for i,col in enumerate(cols):\n",
    "        y_r = X_[:,i]\n",
    "        X_tmp = np.delete(X_,i,axis=1)\n",
    "        m , n = X_tmp.shape\n",
    "        X1 = np.ones((m,n+1))\n",
    "        X1[:,1:] = X_tmp\n",
    "        theta = np.linalg.pinv(X1.T@X1)@(X1.T@y_r) \n",
    "        y_p = X1@theta\n",
    "        ssr = np.sum((y_r-y_p)**2)\n",
    "        sst = np.sum((y_r - np.mean(y_r))**2)\n",
    "        r2 = 1 - ssr/sst\n",
    "        vif[col] = 1/(1-r2)\n",
    "    return pd.Series(vif)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    datos = load_breast_cancer()\n",
    "    df = pd.DataFrame(datos.data,columns=datos.feature_names)\n",
    "    features = ['mean radius', 'mean texture', 'mean perimeter', \n",
    "            'mean area', 'mean smoothness', 'mean compactness']\n",
    "    X = df[features].values ; print(f\"X\\n{X}\")\n",
    "    y = datos.target ; print(f\"y\\n{y}\")\n",
    "    X_train, X_test, y_train, y_test = separar_datos(X,y,0.2)   #= train_test_split(X, y, test_size=0.20, random_state=42)  # 3. Dividiendo en X_train,X_test,y_train,y_test \n",
    "    u = X_train.mean(axis=0)\n",
    "    s = X_train.std(axis=0)\n",
    "    X_train_norm = (X_train - u) / s        #X−1μT , 1:matriz de unos   u:medias                 # 4 . Escalamos , (x- media)/desviacion\n",
    "    X_test_norm = (X_test - u) / s \n",
    "    print(vif_(pd.DataFrame(X_train_norm,columns= features)))\n",
    "    m ,n = X_train_norm.shape\n",
    "    X1 = np.ones((m,n+1))\n",
    "    X1[:,1:] = X_train_norm\n",
    "    theta = descenso_gradiente_logistica_L2(X1,y_train)\n",
    "    print(f\"theta:\\n{theta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5119f-1b5c-48ae-a445-85677c9ab270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
