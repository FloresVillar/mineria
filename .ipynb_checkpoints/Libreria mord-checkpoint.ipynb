{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4fba294-d2b9-4d22-8684-ef4895bb2e01",
   "metadata": {},
   "source": [
    "La librería **`mord`** es una extensión de Python diseñada específicamente para el análisis de **datos ordinales**. Su nombre es un acrónimo de **M**ulticlass and **OR**dinal **D**ata.\n",
    "\n",
    "Como vimos en el capítulo del libro, mientras que la regresión logística estándar (disponible en `scikit-learn`) está pensada para clasificar categorías que no tienen una relación entre sí (como \"manzana\", \"pera\", \"naranja\"), **`mord`** se especializa en categorías que tienen un **orden lógico** (como \"bajo\", \"medio\", \"alto\").\n",
    "\n",
    "Aquí te detallo sus características principales:\n",
    "\n",
    "### 1. ¿Cuál es su propósito principal?\n",
    "Cierra la brecha entre la **clasificación** y la **regresión**:\n",
    "*   **La clasificación tradicional** ignora el orden (trata a las clases como nombres aislados).\n",
    "*   **La regresión lineal** asume que la distancia entre \"1\" y \"2\" es exactamente la misma que entre \"2\" y \"3\", lo cual no siempre es cierto en escalas subjetivas.\n",
    "*   **`mord`** respeta el orden de las categorías sin asumir que los \"escalones\" entre ellas son del mismo tamaño.\n",
    "\n",
    "### 2. Modelos clave incluidos en la librería\n",
    "Los modelos más comunes que ofrece (y que se mencionan en el texto) son:\n",
    "\n",
    "*   **`LogisticIT` (Immediate Threshold):** Es el modelo de **odds proporcionales**. Es el más usado y el que aparece en el ejemplo del libro para los accidentes. Calcula un solo coeficiente por variable y define \"umbrales\" para separar las categorías.\n",
    "*   **`LogisticAT` (All Threshold):** Similar al anterior, pero utiliza una función de pérdida diferente que a veces es más robusta para ciertos tipos de datos.\n",
    "*   **`OrdinalRidge`:** Una versión de la regresión Ridge (con penalización para evitar el sobreajuste) adaptada para rangos ordinales.\n",
    "*   **`LAD` (Least Absolute Deviation):** Un clasificador ordinal que busca minimizar el error absoluto en lugar del error cuadrático.\n",
    "\n",
    "### 3. ¿Por qué se usa en el libro?\n",
    "En el ejercicio de los accidentes (Sección 10.5), la gravedad se mide como:\n",
    "*   0 = Sin heridos\n",
    "*   1 = Heridos no fatales\n",
    "*   2 = Fatalidades\n",
    "\n",
    "Es obvio que hay una progresión. Usar `mord.LogisticIT` permite que el modelo sea más **parsimonioso**. En lugar de calcular muchas ecuaciones (una para cada clase), calcula una sola tendencia y estima en qué punto de esa tendencia se pasa de un \"accidente leve\" a uno \"grave\".\n",
    "\n",
    "### 4. Relación con `scikit-learn`\n",
    "Una gran ventaja de `mord` es que es totalmente compatible con el ecosistema de **scikit-learn**. Esto significa que:\n",
    "1.  Utiliza la misma sintaxis: `.fit(X, y)` para entrenar y `.predict(X)` para predecir.\n",
    "2.  Se puede integrar fácilmente en *Pipelines* y procesos de *Cross-Validation*.\n",
    "\n",
    "### Resumen Técnico\n",
    "Si tienes una variable objetivo que es una **escala** (estrellas de una reseña, niveles de dolor, rangos salariales, encuestas de satisfacción), **`mord`** es la herramienta correcta porque es matemáticamente más precisa para capturar la jerarquía de esos datos que un modelo nominal común."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
